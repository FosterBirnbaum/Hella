# SeeR Model Zoo Web App
**Note: The Model Zoo is only compatible with Python 3**

The SeeR Model Zoo is a web application to showcase the results of different anomaly detection models running on different datasets. The app is designed to automatically enable "plug and play" of different anomaly detection models on different packet-capture datasets.

To add a model, add the `.pkl` file for the model (generated using `model.save`) to the `models/` directory. Name the model something informative using Python function naming conventions, because the web app will automatically pretty print the name given (e.g. `isolation_forest_contextual.pkl` will be pretty-printed as "Isolation Forest Contextual". The model must reference a valid featurizer (`model.featurizer`). Note that this featurizer is not actually contained within the `.pkl` file, which only contains a reference to the function in other code. Then the featurizer corresponding to a model must be kept in place even after new models have been built.

To add a dataset, wrap it in the `Test_data` class, pickle it using the pickle module and `pickle.dump`, and then add it to the `datasets/` directory, following the same naming convention mentioned above.

After adding a model/dataset, you will need to update the corresponding `info.json` file within the `models/` or `/datasets` directories to add a small description for your
new model or dataset.

## Setup

*TODO: add support for getting code without git clone*

Must be run using Python 3.

 1. Clone: `git clone https://github.com/cs210/Hella.git`
 2. Create a virtualenv: `virtualenv .env`
 3. Activate the virtualenv: `source .env/bin/activate` (or `.env/Script/activate` if you're on Windows)
 4. `pip install -r requirements.txt`
 5. Get sample models and datasets: `cd zoo` and `sh get_data.sh`
 6. Run the web app locally: `cd ..` and `python run-zoo.py`
 7. Navigate to your localhost: http://127.0.0.0:8000

## Sample Models and Datasets
By default, the SeeR Model Zoo comes pre-packaged with some ready-made packet captures and models which you can play around with -- we host these on Google Drive and they can be downloaded with the `get_data.sh` script.  If you followed the instructions in the previous section, you will already have these models and packet captures in your `models/` and `datasets/` directories.

Our sample datasets were generated by obtaining a packet capture of API requests made by a simulated vehicle trajectory.

*TODO: include more information about our sample datasets and models.*
