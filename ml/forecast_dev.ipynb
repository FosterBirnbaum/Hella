{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Forecasting Model\n",
    "\n",
    "O'Reilly Machine Learning and Security\n",
    "* https://github.com/oreilly-mlsec/mlsec.net\n",
    "\n",
    "Chapter 3 Resources\n",
    "* https://github.com/oreilly-mlsec/book-resources/blob/master/chapter3/lstm-anomaly-detection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading data...\")\n",
    "reader = read_tcpdump_file('data/week1_friday.tcpdump')\n",
    "packets = np.array([f for f in featurize_packets(reader)])\n",
    "\n",
    "print(\"standardizing data... (impossible given protocol is invariable)\")\n",
    "means = np.apply_along_axis(np.mean, 0, packets)\n",
    "stds = np.apply_along_axis(np.std, 0, packets)\n",
    "packets -= means\n",
    "packets /= stds\n",
    "\n",
    "print(\"done.\")\n",
    "\n",
    "# TODO: cull non-continuous variables OR manually define loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 50\n",
    "sequence_length = 4\n",
    "features = 14\n",
    "mean_window = 40\n",
    "loss_tolerance = 2\n",
    "train_test_split = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastModel(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = self.generate_model()\n",
    "    \n",
    "    def generate_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(LSTM(input_shape=(sequence_length - 1, features), \n",
    "                       units=32, \n",
    "                       return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(LSTM(units=128,\n",
    "                       return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(LSTM(units=100,\n",
    "                       return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Dense(units=features))\n",
    "        model.add(Activation('linear'))\n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def prepare_data(self, data, training=True):\n",
    "        \n",
    "        if training:\n",
    "\n",
    "            print('creating train n-grams...')\n",
    "\n",
    "            train_grams = []\n",
    "            for i in range(0, len(data) - sequence_length):\n",
    "                train_grams.append(data[i: i + sequence_length])\n",
    "            train_grams = np.array(train_grams)\n",
    "\n",
    "            print('train data shape : ', train_grams.shape)\n",
    "\n",
    "            self.x_train = train_grams[:, :-1]\n",
    "            self.y_train = train_grams[:, -1]\n",
    "\n",
    "        else:\n",
    "\n",
    "            print('creating test n-grams...')\n",
    "\n",
    "            test_grams = []\n",
    "            for i in range(0, len(data) - sequence_length):\n",
    "                test_grams.append(data[i: i + sequence_length])\n",
    "            test_grams = np.array(test_grams)\n",
    "\n",
    "            print('test data shape : ', test_grams.shape)  \n",
    "\n",
    "            self.x_test = test_grams[:, :-1]\n",
    "            self.y_test = test_grams[:, -1]        \n",
    "    \n",
    "    def train(self, data):\n",
    "        \n",
    "        self.prepare_data(data)\n",
    "        self.train_history = self.model.fit(self.x_train, self.y_train,\n",
    "                                            batch_size=batch_size, epochs=epochs)\n",
    "        \n",
    "    def test(self, data):\n",
    "        \n",
    "        assert self.train_history is not None \n",
    "        \n",
    "        self.prepare_data(data, training=False)\n",
    "        \n",
    "        losses_in_window = deque()\n",
    "        moving_mean = 0\n",
    "        rolling_std = 0\n",
    "        \n",
    "        for i in range(self.x_test.shape[0]):\n",
    "            \n",
    "            test_loss = self.model.evaluate(x=np.expand_dims(self.x_test[i], 0), \n",
    "                                            y=np.expand_dims(self.y_test[i], 0), batch_size=1)\n",
    "            \n",
    "            if i < mean_window:\n",
    "                moving_mean += test_loss / mean_window\n",
    "                losses_in_window.append(test_loss)\n",
    "                print(\"build mean\")\n",
    "            else:\n",
    "                moving_mean += (test_loss - losses_in_window[0]) / mean_window\n",
    "                losses_in_window.popleft()\n",
    "                losses_in_window.append(test_loss)\n",
    "                \n",
    "                # not efficient\n",
    "                rolling_std = np.std(losses_in_window)\n",
    "                \n",
    "                if np.abs(test_loss - moving_mean) < rolling_std * loss_tolerance:\n",
    "                    print(\"all clear\")\n",
    "                else:\n",
    "                    print(\"\\nMALICIOUS\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train n-grams...\n",
      "train data shape :  (96, 4, 14)\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 659571.1680\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 353us/step - loss: 659311.6862\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 434us/step - loss: 658754.6549\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 365us/step - loss: 657576.6107\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 534us/step - loss: 655627.9609\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 492us/step - loss: 653331.4115\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 469us/step - loss: 652108.1862\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 416us/step - loss: 651500.1146\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 527us/step - loss: 651040.4492\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 441us/step - loss: 650634.9310\n"
     ]
    }
   ],
   "source": [
    "model = ForecastModel()\n",
    "\n",
    "split = (len(packets) * train_test_split) // 10\n",
    "\n",
    "model.train(packets[:split])\n",
    "model.test(packets[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
