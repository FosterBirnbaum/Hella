{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Forecasting Model\n",
    "\n",
    "O'Reilly Machine Learning and Security\n",
    "* https://github.com/oreilly-mlsec/mlsec.net\n",
    "\n",
    "Chapter 3 Resources\n",
    "* https://github.com/oreilly-mlsec/book-resources/blob/master/chapter3/lstm-anomaly-detection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading data...\")\n",
    "reader = read_tcpdump_file('data/week1_friday.tcpdump')\n",
    "packets = np.array([f for f in featurize_packets(reader)])\n",
    "\n",
    "print(\"standardizing data... (impossible given protocol is invariable)\")\n",
    "means = np.apply_along_axis(np.mean, 0, packets)\n",
    "stds = np.apply_along_axis(np.std, 0, packets)\n",
    "packets -= means\n",
    "packets /= stds\n",
    "\n",
    "print(\"done.\")\n",
    "\n",
    "# TODO: cull non-continuous variables OR manually define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(packets[0]-packets[1])\n",
    "print(packets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 50\n",
    "sequence_length = 4\n",
    "features = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastModel(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = self.generate_model()\n",
    "    \n",
    "    def generate_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(LSTM(input_shape=(sequence_length - 1, features), \n",
    "                       units=32, \n",
    "                       return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(LSTM(units=128,\n",
    "                       return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(LSTM(units=100,\n",
    "                       return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Dense(units=features))\n",
    "        model.add(Activation('linear'))\n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def prepare_data(self, data, train_start, train_end, test_start, test_end):\n",
    "        \n",
    "        print('creating train n-grams...')\n",
    "        \n",
    "        train_grams = []\n",
    "        for i in range(train_start, train_end - sequence_length):\n",
    "            train_grams.append(data[i: i + sequence_length])\n",
    "        train_grams = np.array(train_grams)\n",
    "        \n",
    "        print('train data shape : ', train_grams.shape)\n",
    "        \n",
    "        self.x_train = train_grams[:, :-1]\n",
    "        self.y_train = train_grams[:, -1]\n",
    "\n",
    "\n",
    "        print('creating test n-grams...')\n",
    "        \n",
    "        test_grams = []\n",
    "        for i in range(test_start, test_end - sequence_length):\n",
    "            test_grams.append(data[i: i + sequence_length])\n",
    "        test_grams = np.array(test_grams)\n",
    "        \n",
    "        print('test data shape : ', test_grams.shape)  \n",
    "        \n",
    "        self.x_test = test_grams[:, :-1]\n",
    "        self.y_test = test_grams[:, -1]        \n",
    "    \n",
    "    def run(self, data):\n",
    "        \n",
    "        self.prepare_data(data, 0, 10000, 10000, 15000)\n",
    "        self.model.fit(self.x_train, self.y_train,\n",
    "                  batch_size=batch_size, epochs=epochs)\n",
    "        \n",
    "        # TODO: implement train vs. test\n",
    "        # TODO: implement test statistics\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ForecastModel()\n",
    "model.run(packets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
